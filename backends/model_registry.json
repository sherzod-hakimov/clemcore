[
  {
      "model_name": "openchat",
      "model_id": "openchat-3.5-0106",
      "backend": "openai_compatible",
      "release_date": "2024-01-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "codellama-34b",
      "model_id": "codellama-34b-instruct",
      "backend": "openai_compatible",
      "release_date": "2023-08-24",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "Llama-3-70B-Instruct-Anyscale",
      "model_id": "meta-llama/Meta-Llama-3-70B-Instruct",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Llama-3-70B-Together.ai",
      "model_id": "meta-llama/Llama-3-70b-chat-hf",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Llama-3-8B-Together.ai",
      "model_id": "meta-llama/Llama-3-8b-chat-hf",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "Llama-3-8B-Instruct-Anyscale",
      "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
      "backend": "openai_compatible",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "Meta-Llama-3.1-405B-Instruct-Turbo",
      "model_id": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
      "backend": "openai_compatible",
      "release_date": "2024-07-23",
      "open_weight": true,
      "parameters": "405B"
  },
  {
      "model_name": "Mixtral-8x22B-Instruct-v0.1",
      "model_id": "mistralai/Mixtral-8x22B-Instruct-v0.1",
      "backend": "openai_compatible",
      "release_date": "2024-04-17",
      "open_weight": true,
      "parameters": "141B"
  },
  {
      "model_name": "Mixtral-8x7B-Instruct-v0.1",
      "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "backend": "openai_compatible",
      "release_date": "2023-12-11",
      "open_weight": true,
      "parameters": "46.7B"
  },
  {
      "model_name": "fsc-openchat-3.5-0106",
      "model_id": "openchat-3.5-0106",
      "backend": "openai_compatible",
      "release_date": "2024-01-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "fsc-codellama-34b-instruct",
      "model_id": "codellama-34b-instruct",
      "backend": "openai_compatible",
      "release_date": "2023-08-24",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "gpt-4-1106-vision-preview",
      "model_id": "gpt-4-1106-vision-preview",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2023-11-06",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "1.76T"
  },
  {
      "model_name": "gpt-4o-2024-05-13",
      "model_id": "gpt-4o-2024-05-13",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-05-13",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "200B"
  },
  {
      "model_name": "gpt-4o-2024-08-06",
      "model_id": "gpt-4o-2024-08-06",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-08-06",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "200B"
  },
  {
      "model_name": "gpt-4o-mini-2024-07-18",
      "model_id": "gpt-4o-mini-2024-07-18",
      "backend": "openai",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-07-18",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": "8B"
  },
  {
      "model_name": "gpt-4-turbo-2024-04-09",
      "model_id": "gpt-4-turbo-2024-04-09",
      "backend": "openai",
      "release_date": "2024-04-09",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-4-1106-preview",
      "model_id": "gpt-4-1106-preview",
      "backend": "openai",
      "release_date": "2023-11-06",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-4-0125-preview",
      "model_id": "gpt-4-0125-preview",
      "backend": "openai",
      "release_date": "2024-01-25",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "o1-preview-2024-09-12",
      "model_id": "o1-preview-2024-09-12",
      "backend": "openai",
      "release_date": "2024-09-12",
      "open_weight": false,
      "parameters": "",
      "o1_model": true
  },
  {
      "model_name": "o1-mini-2024-09-12",
      "model_id": "o1-mini-2024-09-12",
      "backend": "openai",
      "release_date": "2024-09-12",
      "open_weight": false,
      "parameters": "",
      "o1_model": true
  },
  {
      "model_name": "gpt-3.5-turbo-0125",
      "model_id": "gpt-3.5-turbo-0125",
      "backend": "openai",
      "release_date": "2024-01-25",
      "open_weight": false,
      "parameters": "175B"
  },
  {
      "model_name": "gpt-4-0613",
      "model_id": "gpt-4-0613",
      "backend": "openai",
      "release_date": "2023-06-13",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-4-0314",
      "model_id": "gpt-4-0314",
      "backend": "openai",
      "release_date": "2023-03-14",
      "open_weight": false,
      "parameters": "1.76T"
  },
  {
      "model_name": "gpt-3.5-turbo-1106",
      "model_id": "gpt-3.5-turbo-1106",
      "backend": "openai",
      "release_date": "2023-11-06",
      "open_weight": false,
      "parameters": "175B"
  },
  {
      "model_name": "gpt-3.5-turbo-0613",
      "model_id": "gpt-3.5-turbo-0613",
      "backend": "openai",
      "release_date": "2023-06-13",
      "open_weight": false,
      "parameters": "175B"
  },
  {
      "model_name": "mistral-medium-2312",
      "model_id": "mistral-medium-2312",
      "backend": "mistral",
      "release_date": "2023-12-01",
      "open_weight": true,
      "parameters": "",
      "estimated_parameters": "141B"
  },
  {
      "model_name": "mistral-tiny-2312",
      "model_id": "mistral-tiny-2312",
      "backend": "mistral",
      "release_date": "2023-12-01",
      "open_weight": true,
      "parameters": "",
      "estimated_parameters": "7B"
  },
  {
      "model_name": "mistral-small-2312",
      "model_id": "mistral-small-2312",
      "backend": "mistral",
      "release_date": "2023-12-01",
      "open_weight": true,
      "parameters": "",
      "estimated_parameters": "46.7B"
  },
  {
      "model_name": "mistral-large-2402",
      "model_id": "mistral-large-2402",
      "backend": "mistral",
      "release_date": "2024-02-01",
      "open_weight": true,
      "parameters": "123B"
  },
  {
      "model_name": "command",
      "model_id": "command",
      "backend": "cohere",
      "release_date": "2022-12-01",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "command-r",
      "model_id": "command-r",
      "backend": "cohere",
      "release_date": "2024-03-01",
      "open_weight": true,
      "parameters": "35B"
  },
  {
      "model_name": "command-r-plus",
      "model_id": "command-r-plus",
      "backend": "cohere",
      "release_date": "2024-04-01",
      "open_weight": true,
      "parameters": "104B"
  },
  {
      "model_name": "command-light",
      "model_id": "command-light",
      "backend": "cohere",
      "release_date": "2022-12-01",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-v1.3",
      "model_id": "claude-v1.3",
      "backend": "anthropic",
      "release_date": "2023-04-18",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-v1.3-100k",
      "model_id": "claude-v1.3-100k",
      "backend": "anthropic",
      "release_date": "2023-03-18",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-instant-1.2",
      "model_id": "claude-instant-1.2",
      "backend": "anthropic",
      "release_date": "2023-08-09",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "claude-2",
      "model_id": "claude-2",
      "backend": "anthropic",
      "release_date": "2023-07-11",
      "open_weight": false,
      "parameters": "137B"
  },
  {
      "model_name": "claude-2.1",
      "model_id": "claude-2.1",
      "backend": "anthropic",
      "release_date": "2023-11-21",
      "open_weight": false,
      "parameters": "137B"
  },
  {
      "model_name": "claude-3-opus-20240229",
      "model_id": "claude-3-opus-20240229",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-02-29",
      "open_weight": false,
      "parameters": "2T"
  },
  {
      "model_name": "claude-3-sonnet-20240229",
      "model_id": "claude-3-sonnet-20240229",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-02-29",
      "open_weight": false,
      "parameters": "70B"
  },
  {
      "model_name": "claude-3-haiku-20240307",
      "model_id": "claude-3-haiku-20240307",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-03-07",
      "open_weight": false,
      "parameters": "20B"
  },
  {
      "model_name": "claude-3-5-sonnet-20240620",
      "model_id": "claude-3-5-sonnet-20240620",
      "backend": "anthropic",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-06-20",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.0-pro-001",
      "model_id": "gemini-1.0-pro-001",
      "backend": "google",
      "release_date": "2024-02-15",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.0-pro-002",
      "model_id": "gemini-1.0-pro-002",
      "backend": "google",
      "release_date": "2024-04-09",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.0-pro-vision-001",
      "model_id": "gemini-1.0-pro-vision-latest",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-02-15",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.5-flash-001",
      "model_id": "gemini-1.5-flash-001",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-05-24",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.5-pro-001",
      "model_id": "gemini-1.5-pro-001",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-05-24",
      "open_weight": false,
      "parameters": "1.5T"
  },
  {
      "model_name": "gemini-1.5-pro-002",
      "model_id": "gemini-1.5-pro-002",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-09-24",
      "open_weight": false,
      "parameters": "1.5T"
  },
  {
      "model_name": "gemini-1.5-flash-002",
      "model_id": "gemini-1.5-flash-002",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-09-24",
      "open_weight": false,
      "parameters": "",
      "estimated_parameters": ""
  },
  {
      "model_name": "gemini-1.5-flash-8b-001",
      "model_id": "gemini-1.5-flash-8b-001",
      "backend": "google",
      "supports_images": true,
      "support_multiple_images": true,
      "release_date": "2024-10-03",
      "open_weight": false,
      "parameters": "8B"
  },
  {
      "model_name": "luminous-supreme-control",
      "model_id": "luminous-supreme-control",
      "backend": "alephalpha",
      "release_date": "2023-02-13",
      "open_weight": false,
      "parameters": "70B"
  },
  {
      "model_name": "luminous-supreme",
      "model_id": "luminous-supreme",
      "backend": "alephalpha",
      "release_date": "2022-08-15",
      "open_weight": false,
      "parameters": "70B"
  },
  {
      "model_name": "luminous-extended",
      "model_id": "luminous-extended",
      "backend": "alephalpha",
      "release_date": "2022-06-15",
      "open_weight": false,
      "parameters": "30B"
  },
  {
      "model_name": "luminous-base",
      "model_id": "luminous-base",
      "backend": "alephalpha",
      "release_date": "2022-04-14",
      "open_weight": false,
      "parameters": "13B"
  },
  {
      "model_name": "Mistral-7B-Instruct-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "mistralai/Mistral-7B-Instruct-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-09-27",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "sheep-duck-llama-2-70b-v1.1",
      "backend": "huggingface_local",
      "huggingface_id": "Riiid/sheep-duck-llama-2-70b-v1.1",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-09-27",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "sheep-duck-llama-2-13b",
      "backend": "huggingface_local",
      "huggingface_id": "Riiid/sheep-duck-llama-2-13b",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### User:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'system' %}{{ '### System:\\n' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant:\\n' + message['content'] + '\\n\\n' }}{% endif %}{% if loop.last %}{{ '### Assistant:\\n' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-10-04",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "falcon-7b-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "tiiuae/falcon-7b-instruct",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-04-25",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "falcon-40b-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "tiiuae/falcon-40b-instruct",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-05-25",
      "open_weight": true,
      "parameters": "40B"
  },
  {
      "model_name": "oasst-sft-4-pythia-12b-epoch-3.5",
      "backend": "huggingface_local",
      "huggingface_id": "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '<|prompter|>' + message['content'] + '<|endoftext|>' }}{% elif message['role'] == 'assistant' %}{{ '<|assistant|>' + message['content'] + '<|endoftext|>' }}{% endif %}{% if loop.last %}{{ '<|assistant|>' }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-04-03",
      "open_weight": true,
      "parameters": "12B"
  },
  {
      "model_name": "koala-13B-HF",
      "backend": "huggingface_local",
      "huggingface_id": "TheBloke/koala-13B-HF",
      "premade_chat_template": false,
      "custom_chat_template": "{{ 'BEGINNING OF CONVERSATION: ' }}{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + ' ' }}{% elif message['role'] == 'assistant' %}{{ 'GPT: ' + message['content'] + ' ' }}{% endif %}{% if loop.last %}{{ 'GPT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-04-07",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "Wizard-Vicuna-13B-Uncensored-HF",
      "backend": "huggingface_local",
      "huggingface_id": "TheBloke/Wizard-Vicuna-13B-Uncensored-HF",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-05-13",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "WizardLM-70b-v1.0",
      "backend": "huggingface_local",
      "huggingface_id": "WizardLM/WizardLM-70b-v1.0",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-08-09",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "WizardLM-13b-v1.2",
      "backend": "huggingface_local",
      "huggingface_id": "WizardLM/WizardLM-13b-v1.2",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-07-25",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "vicuna-7b-v1.5",
      "backend": "huggingface_local",
      "huggingface_id": "lmsys/vicuna-7b-v1.5",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-07-29",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "vicuna-13b-v1.5",
      "backend": "huggingface_local",
      "huggingface_id": "lmsys/vicuna-13b-v1.5",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-07-29",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "vicuna-33b-v1.3",
      "backend": "huggingface_local",
      "huggingface_id": "lmsys/vicuna-33b-v1.3",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-06-21",
      "open_weight": true,
      "parameters": "33B"
  },
  {
      "model_name": "gpt4all-13b-snoozy",
      "backend": "huggingface_local",
      "huggingface_id": "nomic-ai/gpt4all-13b-snoozy",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ 'USER: ' + message['content'] + '\\n' }}{% elif message['role'] == 'assistant' %}{{ 'ASSISTANT: ' + message['content'] + '</s>\\n' }}{% endif %}{% if loop.last %}{{ 'ASSISTANT:' }}{% endif %}{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-04-24",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "CodeLlama-34b-Instruct-hf",
      "backend": "huggingface_local",
      "huggingface_id": "codellama/CodeLlama-34b-Instruct-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-08-24",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "zephyr-7b-alpha",
      "backend": "huggingface_local",
      "huggingface_id": "HuggingFaceH4/zephyr-7b-alpha",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-10-09",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "zephyr-7b-beta",
      "backend": "huggingface_local",
      "huggingface_id": "HuggingFaceH4/zephyr-7b-beta",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-10-26",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "openchat_3.5",
      "backend": "huggingface_local",
      "huggingface_id": "openchat/openchat_3.5",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2023-10-30",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Yi-34B-Chat",
      "backend": "huggingface_local",
      "huggingface_id": "01-ai/Yi-34B-Chat",
      "premade_chat_template": true,
      "slow_tokenizer": true,
      "output_split_prefix": "assistant\n",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2023-11-22",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "deepseek-llm-7b-chat",
      "backend": "huggingface_local",
      "huggingface_id": "deepseek-ai/deepseek-llm-7b-chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\uff5cend\u2581of\u2581sentence\uff5c>",
      "release_date": "2023-11-29",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "deepseek-llm-67b-chat",
      "backend": "huggingface_local",
      "huggingface_id": "deepseek-ai/deepseek-llm-67b-chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\uff5cend\u2581of\u2581sentence\uff5c>",
      "release_date": "2023-11-29",
      "open_weight": true,
      "parameters": "67B"
  },
  {
      "model_name": "tulu-2-dpo-7b",
      "backend": "huggingface_local",
      "huggingface_id": "allenai/tulu-2-dpo-7b",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-11-13",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "tulu-2-dpo-70b",
      "backend": "huggingface_local",
      "huggingface_id": "allenai/tulu-2-dpo-70b",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}\n{% if message['role'] == 'user' %}\n{{ '<|user|>\n' + message['content'] }}\n{% elif message['role'] == 'assistant' %}\n{{ '<|assistant|>\n'  + message['content'] + eos_token }}\n{% endif %}\n{% if loop.last %}\n{{ '<|assistant|>' }}\n{% endif %}\n{% endfor %}",
      "eos_to_cull": "</s>",
      "release_date": "2023-11-12",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Mixtral-8x7B-Instruct-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-12-11",
      "open_weight": true,
      "parameters": "46.7B"
  },
  {
      "model_name": "SUS-Chat-34B",
      "backend": "huggingface_local",
      "huggingface_id": "SUSTech/SUS-Chat-34B",
      "premade_chat_template": false,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{{ '### Human: ' + message['content'] + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Assistant: ' + message['content'] }}{% endif %}{% if loop.last %}{{ '### Assistant: ' }}{% endif %}{% endfor %}",
      "slow_tokenizer": true,
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2023-11-29",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "CodeLlama-70b-Instruct-hf",
      "backend": "huggingface_local",
      "huggingface_id": "codellama/CodeLlama-70b-Instruct-hf",
      "premade_chat_template": true,
      "eos_to_cull": "<step>",
      "release_date": "2024-01-29",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "openchat-3.5-0106",
      "backend": "huggingface_local",
      "huggingface_id": "openchat/openchat-3.5-0106",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2024-01-06",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "openchat-3.5-1210",
      "backend": "huggingface_local",
      "huggingface_id": "openchat/openchat-3.5-1210",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2023-12-10",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Nous-Hermes-2-Mixtral-8x7B-DPO",
      "backend": "huggingface_local",
      "huggingface_id": "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-11",
      "open_weight": true,
      "parameters": "46.7B"
  },
  {
      "model_name": "Smaug-72B-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "abacusai/Smaug-72B-v0.1",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2024-02-02",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Smaug-34B-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "abacusai/Smaug-34B-v0.1",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\n' + system_message + '\n<</SYS>>\n\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}",
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2024-01-25",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "Qwen1.5-7B-Chat",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen1.5-7B-Chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-30",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen1.5-72B-Chat",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen1.5-72B-Chat",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-30",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Swallow-70b-instruct-v0.1",
      "backend": "huggingface_local",
      "huggingface_id": "tokyotech-llm/Swallow-70b-instruct-v0.1",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-12-19",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Phi-3-mini-128k-instruct",
      "backend": "huggingface_local",
      "huggingface_id": "microsoft/Phi-3-mini-128k-instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|endoftext\\|>",
      "release_date": "2024-04-22",
      "open_weight": true,
      "parameters": "3.8B"
  },
  {
      "model_name": "Starling-LM-7B-beta",
      "backend": "huggingface_local",
      "huggingface_id": "Nexusflow/Starling-LM-7B-beta",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2024-03-19",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen2-7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2-7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-06-04",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen2-72B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2-72B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-05-28",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Llama-3-SauerkrautLM-70b-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "VAGOsolutions/Llama-3-SauerkrautLM-70b-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-04-24",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "aya-23-8B",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "CohereForAI/aya-23-8B",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-05-19",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "aya-23-35B",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "CohereForAI/aya-23-35B",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-05-19",
      "open_weight": true,
      "parameters": "35B"
  },
  {
      "model_name": "gemma-2-9b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-2-9b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<end_of_turn>\n*<eos>",
      "release_date": "2024-06-24",
      "open_weight": true,
      "parameters": "9B"
  },
  {
      "model_name": "gemma-2-27b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-2-27b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<end_of_turn>\n*<eos>",
      "release_date": "2024-06-24",
      "open_weight": true,
      "parameters": "27B"
  },
  {
      "model_name": "llama-2-7b-chat-hf",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/llama-2-7b-chat-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-07-18",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "llama-2-13b-chat-hf",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/llama-2-13b-chat-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-07-18",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "llama-2-70b-chat-hf",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/llama-2-70b-chat-hf",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2023-07-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "gemma-7b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-7b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-02-21",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "gemma-1.1-2b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-1.1-2b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-03-26",
      "open_weight": true,
      "parameters": "2B"
  },
  {
      "model_name": "gemma-1.1-7b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-1.1-7b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-03-26",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "codegemma-7b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/codegemma-7b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-04-09",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "recurrentgemma-2b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/recurrentgemma-2b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-04-09",
      "open_weight": true,
      "parameters": "2B"
  },
  {
      "model_name": "gemma-2-2b-it",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "google/gemma-2-2b-it",
      "premade_chat_template": true,
      "eos_to_cull": "<eos>",
      "release_date": "2024-07-16",
      "open_weight": true,
      "parameters": "2B"
  },
  {
      "model_name": "Meta-Llama-3.1-8B-Instruct",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-07-23",
      "open_weight": true,
      "parameters": "8B"
  },
  {
      "model_name": "Meta-Llama-3.1-70B-Instruct",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "meta-llama/Meta-Llama-3.1-70B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-07-23",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Mistral-Large-Instruct-2407",
      "backend": "huggingface_local",
      "requires_api_key": true,
      "huggingface_id": "mistralai/Mistral-Large-Instruct-2407",
      "premade_chat_template": true,
      "eos_to_cull": "</s>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "123B"
  },
  {
      "model_name": "Qwen2.5-7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Qwen2.5-14B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-14B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "14B"
  },
  {
      "model_name": "Qwen2.5-32B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-32B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "32B"
  },
  {
      "model_name": "Qwen2.5-72B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "Qwen/Qwen2.5-72B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-07-24",
      "open_weight": true,
      "parameters": "72B"
  },
  {
      "model_name": "Llama-3.2-1B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "meta-llama/Llama-3.2-1B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-09-18",
      "open_weight": false,
      "parameters": "1B"
  },
  {
      "model_name": "Llama-3.2-3B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "meta-llama/Llama-3.2-3B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-09-18",
      "open_weight": false,
      "parameters": "3B"
  },
  {
      "model_name": "EuroLLM-1.7B-Instruct",
      "backend": "huggingface_local",
      "huggingface_id": "utter-project/EuroLLM-1.7B-Instruct",
      "premade_chat_template": true,
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-09-24",
      "open_weight": true,
      "parameters": "1.7B"
  },
  {
      "model_name": "Qwen1.5-0.5B-Chat-GGUF-q8",
      "backend": "llamacpp",
      "huggingface_id": "Qwen/Qwen1.5-0.5B-Chat-GGUF",
      "filename": "*q8_0.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-02-03",
      "open_weight": true,
      "parameters": "0.5B"
  },
  {
      "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q4",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
      "filename": "*Q4_0.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-31",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
      "filename": "*Q5_0.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-31",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "CapybaraHermes-2.5-Mistral-7B-GGUF-q5-k-s",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/CapybaraHermes-2.5-Mistral-7B-GGUF",
      "filename": "*Q5_K_S.gguf",
      "premade_chat_template": true,
      "bos_string": "<s>",
      "eos_string": "<|im_end|>",
      "eos_to_cull": "<\\|im_end\\|>",
      "release_date": "2024-01-31",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "EstopianMaid-13B-GGUF-q2-k",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
      "filename": "*Q2_K.gguf",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
      "bos_string": "<s>",
      "eos_string": "</s>",
      "eos_to_cull": "</s>",
      "release_date": "2024-01-26",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "EstopianMaid-13B-GGUF-q3-k-s",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/EstopianMaid-13B-GGUF",
      "filename": "*Q3_K_S.gguf",
      "premade_chat_template": false,
      "custom_chat_template": "{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'].strip() + '\\n\\n' %}{% else %}{% set loop_messages = messages %}{% set system_message = '' %}{% endif %}{% if system_message %}{{ bos_token + system_message }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{bos_token + '### Instruction:\\n' + message['content'].strip() + '\\n\\n' }}{% elif message['role'] == 'assistant' %}{{ '### Response:\\n' + message['content'].strip() + eos_token + '\\n\\n' }}{% endif %}{% if loop.last and message['role'] == 'user' and add_generation_prompt %}{{ '### Response:\\n' }}{% endif %}{% endfor %}",
      "bos_string": "<s>",
      "eos_string": "</s>",
      "eos_to_cull": "</s>",
      "release_date": "2024-01-26",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "openchat_3.5-GGUF-q5",
      "backend": "llamacpp",
      "huggingface_id": "TheBloke/openchat_3.5-GGUF",
      "filename": "*Q5_0.gguf",
      "premade_chat_template": false,
      "custom_chat_template": "{{ bos_token }}{% for message in messages %}{{ 'GPT4 Correct ' + message['role'].title() + ': ' + message['content'] + '<|end_of_turn|>'}}{% endfor %}{% if add_generation_prompt %}{{ 'GPT4 Correct Assistant:' }}{% endif %}",
      "bos_string": "<s>",
      "eos_string": "<|end_of_turn|>",
      "eos_to_cull": "<\\|end_of_turn\\|>",
      "release_date": "2023-11-02",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q4",
      "backend": "llamacpp",
      "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
      "filename": "*Q4_K_M.gguf",
      "premade_chat_template": true,
      "bos_string": "<|begin_of_text|>",
      "eos_string": "<|eot_id|>",
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "Meta-Llama-3-70B-Instruct-GGUF-q8",
      "backend": "llamacpp",
      "huggingface_id": "MaziyarPanahi/Meta-Llama-3-70B-Instruct-GGUF",
      "filename": "*Q8_0-00001-of-00002.gguf",
      "additional_files": [
          "*Q8_0-00002-of-00002.gguf"
      ],
      "premade_chat_template": true,
      "bos_string": "<|begin_of_text|>",
      "eos_string": "<|eot_id|>",
      "eos_to_cull": "<\\|eot_id\\|>",
      "release_date": "2024-04-18",
      "open_weight": true,
      "parameters": "70B"
  },
  {
      "model_name": "c4ai-command-r-plus-GGUF-q4",
      "backend": "llamacpp",
      "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
      "filename": "*Q4_K_M-00001-of-00002.gguf",
      "additional_files": [
          "*Q4_K_M-00002-of-00002.gguf"
      ],
      "premade_chat_template": true,
      "bos_string": "<BOS_TOKEN>",
      "eos_string": "<|END_OF_TURN_TOKEN|>",
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-04-04",
      "open_weight": true,
      "parameters": "104B"
  },
  {
      "model_name": "c4ai-command-r-plus-GGUF-q8",
      "backend": "llamacpp",
      "huggingface_id": "pmysl/c4ai-command-r-plus-GGUF",
      "filename": "*Q8_0-00001-of-00003.gguf",
      "additional_files": [
          "*Q8_0-00002-of-00003.gguf",
          "*Q8_0-00003-of-00003.gguf"
      ],
      "premade_chat_template": true,
      "bos_string": "<BOS_TOKEN>",
      "eos_string": "<|END_OF_TURN_TOKEN|>",
      "eos_to_cull": "<\\|END_OF_TURN_TOKEN\\|>",
      "release_date": "2024-04-04",
      "open_weight": true,
      "parameters": "104B"
  },
  {
      "model_name": "llava-1.5-7b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-1.5-7b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "ASSISTANT:",
      "custom_chat_template": "{%- for message in messages -%}{% if message['role'] == 'user' %}{% if message['image'] %}\nUSER: <image>\n{{message['content']}}{% else %}\nUSER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}\nASSISTANT:{{message['content']}}{% endif %}{% endfor %}\nASSISTANT:",
      "release_date": "2024-01-03",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "llava-1.5-13b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-1.5-13b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "ASSISTANT:",
      "custom_chat_template": "{%- for message in messages -%}{% if message['role'] == 'user' %}{% if message['image'] %}\nUSER: <image>\n{{message['content']}}{% else %}\nUSER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}\nASSISTANT:{{message['content']}}{% endif %}{% endfor %}\nASSISTANT:",
      "release_date": "2024-01-03",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "llava-v1.6-34b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-v1.6-34b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "assistant",
      "not_fast": true,
      "padding": true,
      "custom_chat_template": "<|im_start|>system\nAnswer the questions.<|im_end|>{%- for message in messages -%}{% if message['role'] == 'user' %}{% if message['image']%}<|im_start|>user\n<image>\n{{message['content']}}<|im_end|>{% else %}<|im_start|>\nuser\n{{message['content']}}<|im_end|>{% endif %}{% elif message['role'] == 'assistant' %}<|im_start|>assistant\n{{message['content']}}<|im_end|>{% endif %}{% endfor %}<|im_start|>assistant\n",
      "release_date": "2024-03-17",
      "open_weight": true,
      "parameters": "34B"
  },
  {
      "model_name": "llava-v1.6-mistral-7b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-v1.6-mistral-7b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "[/INST]",
      "padding": true,
      "custom_chat_template": "{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image']%}[INST] <image>\n{{message['content']}} [/INST]{% else %}[INST]\n{{message['content']}} [/INST]{% endif %}{% elif message['role'] == 'assistant' %}{{message['content']}}{% endif %}{% endfor %}",
      "release_date": "2024-02-20",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "llava-v1.6-vicuna-13b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-v1.6-vicuna-13b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "ASSISTANT:",
      "padding": true,
      "custom_chat_template": "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image'] %}USER:<image>\n{{message['content']}}{% else %}USER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}ASSISTANT:{{message['content']}}{% endif %}{% endfor %}ASSISTANT:",
      "release_date": "2024-03-17",
      "open_weight": true,
      "parameters": "13B"
  },
  {
      "model_name": "llava-v1.6-vicuna-7b-hf",
      "backend": "huggingface_multimodal",
      "huggingface_id": "llava-hf/llava-v1.6-vicuna-7b-hf",
      "model_type": "Vision2Seq",
      "output_split_prefix": "ASSISTANT:",
      "padding": true,
      "custom_chat_template": "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.{% for message in messages %}{% if message['role'] == 'user' %}{% if message['image'] %}USER:<image>\n{{message['content']}}{% else %}USER:\n{{message['content']}}{% endif %}{% elif message['role'] == 'assistant' %}ASSISTANT:{{message['content']}}{% endif %}{% endfor %}ASSISTANT:",
      "release_date": "2024-03-17",
      "open_weight": true,
      "parameters": "7B"
  },
  {
      "model_name": "idefics-80b-instruct",
      "backend": "huggingface_multimodal",
      "huggingface_id": "HuggingFaceM4/idefics-80b-instruct",
      "model_type": "Idefics",
      "eos_to_cull": "<end_of_utterance>",
      "output_split_prefix": "Assistant:",
      "supports_multiple_images": true,
      "release_date": "2023-07-24",
      "open_weight": true,
      "parameters": "80B"
  },
  {
      "model_name": "idefics-9b-instruct",
      "backend": "huggingface_multimodal",
      "huggingface_id": "HuggingFaceM4/idefics-9b-instruct",
      "model_type": "Idefics",
      "eos_to_cull": "<end_of_utterance>",
      "output_split_prefix": "Assistant:",
      "supports_multiple_images": true,
      "release_date": "2023-07-24",
      "open_weight": true,
      "parameters": "9B"
  },
  {
    "model_name": "InternVL2-Llama3-76B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-Llama3-76B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "76B"
  },
  {
    "model_name": "InternVL2-40B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-40B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "40B"
  },
  {
    "model_name": "InternVL2-26B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-26B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "26B"
  },
  {
    "model_name": "InternVL2-8B",
    "backend": "huggingface_multimodal",
    "huggingface_id": "OpenGVLab/InternVL2-8B",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.internvl_utils.InternvlMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "use_fast": false,
    "output_split_prefix": "Assistant:",
    "load_in_8bit": false,
    "low_cpu_mem_usage": true,
    "custom_device_map": true,
    "device_map": "backends.multimodal_utils.internvl_utils.split_model",
    "release_date": "2024-07-15",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "internlm-xcomposer2d5-7b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "internlm/internlm-xcomposer2d5-7b",
    "automodel_type": "transformers.AutoModel",
    "model_class": "backends.multimodal_utils.intern_utils.InternlmMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "not_distributed": true,
    "release_date": "2024-07-02",
    "open_weight": true,
    "parameters": "7B"
  },
  {
    "model_name": "Idefics3-8B-Llama3",
    "backend": "huggingface_multimodal",
    "huggingface_id": "HuggingFaceM4/Idefics3-8B-Llama3",
    "automodel_type": "transformers.AutoModelForVision2Seq",
    "model_class": "backends.multimodal_utils.idefics3_utils.Idefics3MLLM",
    "use_tokenizer": false,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": false,
    "output_split_prefix": "Assistant:",
    "low_cpu_mem_usage": true,
    "release_date": "2024-08-05",
    "open_weight": true,
    "parameters": "8B"
  },
  {
    "model_name": "dolphin-vision-72b",
    "backend": "huggingface_multimodal",
    "huggingface_id": "cognitivecomputations/dolphin-vision-72b",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.dolphin_utils.DolphinMLLM",
    "use_tokenizer": true,
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "use_bf16": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-06-28",
    "open_weight": true,
    "parameters": "72B"
  },
  {
    "model_name": "Phi-3.5-vision-instruct",
    "backend": "huggingface_multimodal",
    "huggingface_id": "microsoft/Phi-3.5-vision-instruct",
    "automodel_type": "transformers.AutoModelForCausalLM",
    "model_class": "backends.multimodal_utils.phi_utils.PhiMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": true,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-08-17",
    "open_weight": true,
    "parameters": "4B"
  },
  {
    "model_name": "Pixtral-12B-2409",
    "backend": "huggingface_multimodal",
    "huggingface_id": "mistralai/Pixtral-12B-2409",
    "automodel_type": "vllm.LLM",
    "model_class": "backends.multimodal_utils.pixtral_utils.PixtralMLLM",
    "supports_multiple_images": true,
    "trust_remote_code": false,
    "output_split_prefix": "",
    "low_cpu_mem_usage": true,
    "release_date": "2024-09-11",
    "open_weight": true,
    "parameters": "12B",
    "use_vllm": true,
    "tokenizer_mode": "mistral",
    "vllm_context": 8192
  }
]